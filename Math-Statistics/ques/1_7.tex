\chapter{Достаточные статистики и оптимальные оценки}\label{cha:7}
\section{Определение достаточной статистики}\label{cha:7/sec:1}

\begin{example}\label{cha:7/sec:1/example:1}
	Пусть $X = (X_1, \dots, X_n)$ - н.о.р., $X_1 \sim Pois (\theta)$, $\theta > 0$. Т.е.: 
	$$f(y, \theta) = P_{\theta}(X_1 = y) = \frac{\theta^y}{y!} e^{-\theta}, \;\; y \in \mathcal{X} = \{0, 1, 2, \dots\}$$
	Пусть $T(X) = X_1 + \dots + X_n$. Тогда $T(X) \sim Pois (n \theta)$. Обозначим реализацию $X$ через $x = (x_1, \dots, x_n)$. Тогда условное распределение:
	$$P_{\theta} \left( X \in A | T(X) = t \right) = \underset{x \in A}{\overset{}{\sum}}f_{\theta} (x| t), \text{ где } f_{\theta}(x|t) = \begin{cases}
		P_{\theta}\left( X = x | T(X) = t \right), \; t \in \mathcal{X} \\
		0, \; t \not \in \mathcal{X}
	\end{cases}$$
	Покажем, что \colorbox{DarkSeaGreen}{условное распределение не зависит от $\theta$}. Достаточно проверить, что $f_{\theta} (x|t)$ не зависит от $\theta$. Дальше $t \in \mathcal{X}$.
	\begin{itemize}
		\item[$a)$] 
			Если $T(x) = \underset{i=1}{\overset{n}{\sum}}x_i \not = t$, то $\displaystyle f_{\theta}(x|t) = \dfrac{P\left( X = x, T(X) = t \right)}{P(T(X) = t)} = \emptyset$
		\item[$b)$]
			Если $T(x) = t$, то:
			$$\begin{gathered}
				f_{\theta}(x|t) = \dfrac{P\left( X = x, T(X) = T(x) \right)}{P_{\theta}(T(X) = t)} = \dfrac{P_{\theta}(X = x)}{P_{\theta}(T(X) = t)} = \dfrac{\underset{i=1}{\overset{n}{\Pi}}P_{\theta}(X_i = x_i)}{P_{\theta}(T(X) = t)} = \\
				= \dfrac{\theta^{\underset{i=1}{\overset{n}{\sum}}x_i} e^{-n \theta} t!}{x_1! \dots x_n! (n \theta)^t e^{-n \theta}} = \dfrac{t!}{x_1! \dots x_n !} \cdot \frac{1}{n^t} \text{ - не зависит от } \theta
			\end{gathered}$$
	\end{itemize}
	Покажем, что \colorbox{DarkSeaGreen}{$I^X (\theta) = I^T (\theta)$}.
	$$i (\theta) = E_{\theta} \left( \frac{\partial}{\partial \theta} \left( \underbrace{\ln \frac{\theta^{X_1}}{X_1!} e^{-\theta}}_{= f(X_1, \theta)} \right) \right)^2 = E_{\theta} \left( \frac{X_1}{\theta} - 1 \right)^2 = \frac{D_{\theta} X_1}{\theta^2} = \frac{\theta}{\theta^2} = \frac{1}{\theta}$$
	Значит $\displaystyle I^X (\theta) = n i(\theta) = \frac{n}{\theta}$.
	$$I^T (\theta) = E_{\theta} \left( \frac{\partial}{\partial \theta} \left( \ln \frac{(n \theta)^T}{T!} e^{-n \theta} \right) \right)^2 = E_{\theta} \left( \frac{T}{\theta} - n \right)^2 = \frac{D_{\theta} T}{\theta^2} = \frac{n \theta}{\theta^2} = \frac{n}{\theta}$$
	Т.е. получаем, что $\displaystyle I^X (\theta) = I^T (\theta)$. Т.е. $T(X) = X_1 + \dots + X_n$ содержит всю информацию Фишера от $\theta$, что и $X!$.
\end{example}

Пусть $X = (X_1, \dots, X_n)$ - наблюдение, $\displaystyle P_X \in \Set{P_{\theta}}{\theta \in \Theta \subseteq \mathbb{R}^k}$. Скалярные или векторные функции $T(X)$ называется статистиками.

\begin{definition}\label{cha:7/def:1}
	Статистика $T(X)$ называется \red{достаточной} для параметра $\theta$, если существует вариант условного распределения $P_{\theta}\left( X \in A | T(X) = t \right)$, не зависящий от $\theta$ при любом $t$.
\end{definition}

\begin{remark}\label{cha:7/remark:1}
	Сделаем несколько комментариев:
	\begin{itemize}
		\item[$1)$]
			Условное распределение $P_{\theta}\left( X \in A | T(X) = t \right)$ можно интерпретировать как распределение $X$ на поверхности $T(x) = t$. Тогда, если $T(X)$ - достаточная, то знание, где выборочная точка $X$ находится на поверзности, не дает никакой дополнительной информации о параметре $\theta$. Т.е. вся информация о параметре $\theta$ содержится в $T(X)$. Для построения оценки $\theta$ достаточно знать $T(X)$, остальные данные, содержащиеся в $X$, бесполезны.
		\item[$2)$]
			Если $T(X)$ - некоторая $($необязательно достаточная$)$ статистика, то при некоторых условиях регулярности $($см. [А.А.Боровков. Матем. статист., §17, теорема 1]$)$ $\displaystyle I^T (\theta) \le I^X (\theta) \; \forall \theta \in \Theta$, где $I^T (\theta)$ и $I^X (\theta)$ - $(k \times k)$-матрицы. Равенство здесь достигается тогда и только тогда, когда $T$ - достаточная. Это точный смысл слов: <<достаточная статистика содержит всю информацию о параметре $\theta$>>, применительно к информации Фишера.
	\end{itemize}
\end{remark}

\section{Критерий факторизации Неймана-Фишера}\label{cha:7/sec:2}

\begin{theorem}[\red{критерий факторизации Неймана-Фишера}]\label{cha:7/the:1}
	Пусть $X$ имеет плотность $p(x, \theta)$ относительно меры $\mu$. Тогда $T(X)$ будет достаточной статистикой для $\theta$ тогда и только тогда, когда
	$$p(x, \theta) = \psi (T(x), \theta) \hbar(x) \text{ для } \mu \text{-п.в. } x \eqno(1)$$
	Здесь $\psi \ge 0$ и $\hbar \ge 0$ зависят только от своих аргументов, $\psi(s, \theta)$ измерима по $s$, $\hbar(x)$ измерима по $x$.
\end{theorem}

\begin{conseq}[]\label{cha:7/conseq:1}
	Если $T$ достаточная, и $u = \varphi (v)$ взаимооднозначна и измерима в обе стороны, то $T_1 = \varphi(T)$ тоже достаточна.
\end{conseq}
\begin{Proof}
	$\displaystyle \psi (T, \theta) = \psi (\varphi^{-1} (T_1), \theta)$.
\end{Proof}

Значит, представление $(1)$ неоднозначно!\\

\noindentДокажем теорему \ref{cha:7/the:1}.
\begin{Proof}
	Докажем для дискретного $X$. Пусть $X$ имеет носитель $\mathcal{X} = (x_1, x_2, \dots)$, не зависящий от $\theta$. Тогда $\mathcal{X}_T = \left( T(x_1), T(x_2), \dots \right)$. Условное распределение:
	$$P_{\theta} \left( X \in A | T(X) = t \right) = \begin{cases}
		\underset{x_i \in A}{\overset{}{\sum}}P_{\theta}\left( X = x_i | T(X) = t \right), \; t \in \mathcal{X}_t \\
		0, \; t \not \in \mathcal{X}_t
	\end{cases}$$
	Значит, условное распределение не зависит от $\theta$ тогда и только тогда, когда условная вероятность $\displaystyle P_{\theta}(X = x | T(X) = t)$ не зависит от $\theta$ для всех $t \in \mathcal{X}_t, \; x \in \mathcal{X}$. Но при $x \in \mathcal{X}, \; t \in \mathcal{X}_t$:
	$$\begin{gathered}
		P_{\theta} \left( X = x | T(X) = t \right) = \dfrac{P_{\theta} (X = x, T(X) = t)}{P_{\theta}(T(X) = t)} = \\
		= \begin{cases}
			\dfrac{P_{\theta}  \overbrace{\left( X = x, T(X) = T(x) \right)}^{(X = x)} }{P_{\theta} (T(X) = T(x))}, \; T(x) = t \\
			0, \; T(x) \not = t
		\end{cases} = \begin{cases}
			\dfrac{P_{\theta}(X = x) }{P_{\theta} (T(X) = T(x))}, \; T(x) = t \\
			0, \; T(x) \not = t
		\end{cases}
	\end{gathered}$$
	Итак, $T(X)$ - достаточная тогда и только тогда, когда
	$$\dfrac{P_{\theta}(X = x) }{P_{\theta} (T(X) = T(x))} \text{ не зависит от } \theta \; \forall x \in \mathcal{X}\eqno(2)$$
	\begin{itemize}
		\item[$1)$]
			Пусть выполнено $(1)$. Тогда, учитывая $P_{\theta} (X = x) = p(x, \theta)$, имеем:
			$$\dfrac{P_{\theta}(X = x) }{P_{\theta} (T(X) = T(x))} \hspace{-4pt}= \hspace{-4pt}\dfrac{\psi (T(x), \theta)\hbar (x)}{\underset{y: T(y) = T(x)}{\overset{}{\sum}}p(y, \theta)} \hspace{-4pt}= \hspace{-4pt}\dfrac{\psi (T(x), \theta)\hbar (x)}{\underset{y: T(y) = T(x)}{\overset{}{\sum}}\psi(T(y), \theta)\hbar (y)} = \dfrac{\hbar (x)}{\underset{y: T(y) = T(x)}{\overset{}{\sum}}\hbar(y)}$$
			Это выражение от $\theta$ не зависит, т.е. $T$ - достаточная $($выполнено $(2)$$)$.
		\item[$2)$]
			Наоборот, пусть выполнено $(2)$. Обозначая дробь в $(2)$ через $\hbar (x)$, получим:
			$$\begin{gathered}
				P_{\theta} (X = x) = \hbar (x) P_{\theta} (T(X) = T(x)), \text{ т.е.} \\
				p(x, \theta) = \hbar (x) \underset{y: T(y) = T(x)}{\overset{}{\sum}}p(y, \theta) = \hbar (x) \psi (T(x), \theta)
			\end{gathered}$$
	\end{itemize}
\end{Proof}

\colorbox{DarkSeaGreen}{Примеры}\\

\begin{itemize}
	\item[$1)$]
		$T(X) = X$ всегда достаточная статистика, ее называют тривиальной. Здесь $\psi (T(x), \theta) = p(x, \theta), \; \hbar (x) = 1$.
	\item[$2)$]
		$X = (X_1, \dots, X_n)$, $\{X_i\}$ - н.о.р., $X_1 \sim Pois (\theta), \; \theta > 0$.
		$$p(x, \theta) = \underset{i=1}{\overset{n}{\Pi}} P_{\theta} (X_i = x_i) = \dfrac{\theta^{\underset{}{\overset{}{\sum}}x_i}}{x_1! \dots x_n!} e^{-n \theta}, \; x  = (x_1, \dots, x_n)$$
		$T(X) = \underset{i=1}{\overset{n}{\sum}}X_i$ - достаточная, $\displaystyle \psi (T(x), \theta) = \theta^{\underset{}{\overset{}{\sum}}x_i}e^{-n \theta}, \; \hbar (x) = \frac{1}{x_1! \dots x_n!}$.
	\item[$3)$]
		$X = (X_1, \dots, X_n)$, $\{X_i\}$ - н.о.р., $X_1 \sim R (0, \theta), \; \theta > 0$.
		$$p(x, \theta) = \begin{cases}
			\frac{1}{\theta^n}, \; x_{(1)} \ge 1, \; x_{(n)} \le \theta \\
			0, \text{ в противном случае}
		\end{cases} = \frac{1}{\theta^n} I(x_{(n)} \le \theta) \cdot I(x_{(1)} \ge 0)$$
		Здесь $\psi (T(x), \theta) = \frac{1}{\theta^n} I(x_{(n)} \le \theta)$ с $T(x) = x_{(n)}$, $\hbar (x) = I(x_{(1)} \ge 0), \; x = (x_1, \dots, x_n), \; x_{(1)} \le x_{(2)} \le \dots \le x_{(n)}$.
	\item[$4)$]
		$X = (X_1, \dots, X_n)$, $\{X_i\}$ - н.о.р., $X_1 \sim N(\theta_1, \theta_2)$ с $\theta_1 \in \mathbb{R}^1$ и $\theta_2 > 0$. Здесь $\theta = (\theta_1, \theta_2)^T$. \\
		Пусть $\displaystyle T(X) = \left( \underset{i=1}{\overset{n}{\sum}}X_i, \underset{i=1}{\overset{n}{\sum}}X_i^2 \right)^2$, тогда $T(X)$ - достаточная статистика для $\theta$. Действительно:
		$$\begin{gathered}
			p(x, \theta) = \left( \frac{1}{\sqrt{2 \pi \theta_2}} \right)^n e^{-\frac{1}{2 \theta_2} \underset{i=1}{\overset{n}{\sum}}(x_i - \theta_1)^2} = \\
			= \left( \frac{1}{\sqrt{2 \pi \theta_2}} \right)^n \hspace{-6pt}exp \hspace{-4pt}\left\{ -\frac{1}{2 \theta_2} \left[ \underset{}{\overset{}{\sum}}x_i^2 - 2 \theta_1 \underset{}{\overset{}{\sum}}x_i + n \theta_1^2 \right] \right\} \hspace{-4pt}= \hspace{-4pt}\psi (T(x), \theta) \hbar(x), \; \hbar(x) = 1
		\end{gathered}$$
		Пусть $\displaystyle T_1 = \left( \overline{X}, S^2 \right)$, где $\displaystyle \overline{X} = n^{-1} \underset{i}{\overset{}{\sum}}X_i$, $\displaystyle S^2 = \frac{1}{n-1} \underset{}{\overset{}{\sum}}(X_i - \overline{X})^2$. Поскольку $\displaystyle S^2 = \frac{n}{n-1} \left( n^{-1}\underset{}{\overset{}{\sum}}X_i^2 - \overline{X}^2 \right)$, то отображение $T(x) \leftrightarrow T_1 (x)$ взаимнооднозначно и измеримо в обе стороны. Значит, $\displaystyle T_1 (x) = \left( \overline{X}, S^2 \right)^T$ - достаточная статистика.
\end{itemize}

\section{Теорема Блекуэла-Рао-Колмогорова}\label{cha:7/sec:3}

\begin{theorem}[\red{Блекуэл-Рао-Колмогоров}]\label{cha:7/the:2}
	Пусть $T = T(X)$ - достаточная статистика,  и $\hat{\tau}_n$ - несмещенная оценка $\tau (\theta) \in \mathbb{R}^m$ с конечной ковариационной матрицей. Тогда функция $\displaystyle \tau_n^* := E_{\theta} (\hat{\tau}_n | T)$ обладает свойствами:
	\begin{itemize}
		\item[$1)$]
			$\tau_n^*$ - несмещенная оценка $\tau (\theta)$ с конечной ковариационной матрицей.
		\item[$2)$]
			$\tau_n^*$ зависит от $X$ лишь через $T(X)$.
		\item[$3)$]
			$\displaystyle D_{\theta} \tau_n^* \le D_{\theta}\hat{\tau}_n$ при всех $\theta \in \Theta$. Равенство возможно тогда и только тогда, когда $\hat{\tau}_n = \tau_n^*$ $P_{\theta}$-п.н. при всех $\theta \in \Theta$.
	\end{itemize}
\end{theorem}
\begin{Proof}
	Докажем \blue{$1)$} и \blue{$2)$}. Если $T$ - достаточная статистика, то борелевская функция $\displaystyle m(t) = E_{\theta} (\hat{\tau}_n | T(x) = t$ от $\theta$ не зависит, т.к. условное распределение $X$ при условии $T(x) = t$ от $\theta$ не зависит. Значит, и $\displaystyle m(T(X)) = E_{\theta} (\hat{\tau}_n| T(X)) = \tau_n^* (X)$ от $\theta$ не зависит (т.е. $\tau_n^*$ - оценка), а от $X$ зависит лишь через $T(X)$.\\
	Далее, $\displaystyle E_{\theta} \tau_n^* = E_{\theta} E_{\theta} (\hat{\tau}_n | T) = E_{\theta} \hat{\tau}_n = \tau(\theta)$ при всех $\theta$ в силу формулы полной вероятности и несмещенности $\hat{\tau}_n (\theta)$.\\
	Наконец, если $\displaystyle E_{\theta} \hat{\tau}_{in}^2 < \infty$, то (см. доказательство утверждения \ref{lec:6/clair:7}):
	$$E_{\theta} \left( \tau_{in}^* \right)^2 = E_{\theta} \left( E_{\theta} \left( \hat{\tau}_{in} | T \right) \right)^2 \le E_{\theta} E_{\theta} \left( \hat{\tau}_{in}^2 | T \right) = E_{\theta} \hat{\tau}_{in}^2 < \infty$$
	$($использовали неравенство Коши-Буняковского$)$\\

	Докажем \blue{$3)$}. Достаточно проверить, что:
	$$\alpha^T D_{\theta} \tau_n^* \alpha \le \alpha^T D_{\theta} \hat{\tau}_n \alpha \; \forall \alpha \in \mathbb{R}^m, \; \forall \theta \in \Theta$$
	Но также мы имеем:
	$$\alpha^T D_{\theta}^* \alpha = \alpha^T E(\tau^* - \tau)(\tau^* - \tau)^T \alpha = E_{\theta} \left( \alpha^T \tau_n^* - \alpha^T \tau \right)^2 = D_{\theta} (\alpha^T \tau_n^*)$$
	Значит, достаточно проверить, что:
	$$D_{\theta}(\alpha^T \tau_n^*) \le D_{\theta} (\alpha^T \hat{\tau}_n) \; \forall \alpha \in \mathbb{R}^m, \; \forall \theta \in \Theta$$
	Но также имеем:
	$$\begin{gathered}
		D (\alpha^t \hat{\tau}_n) = E_{\theta} \left( \alpha^T \hat{\tau}_n - \alpha^T \tau - \alpha^t \tau_n^* + \alpha^T \tau_n^* \right) = \\
		= E_{\theta} \left( \alpha^T \hat{\tau}_n - \alpha^T \tau_n^* \right)^2 + E_{\theta} \left( \alpha^T \tau_n^* - \alpha^T \tau \right)^2 + 2 E_{\theta} \left( \alpha^T \hat{\tau}_n - \alpha^T \tau_n^* \right)\left( \alpha^T \tau_n^* - \alpha^T \tau \right)
	\end{gathered}$$
	Заметим, что:
	$$\begin{gathered}
		2 E_{\theta} E_{\theta} \left(\left( \alpha^T \hat{\tau}_n - \alpha^T \tau_n^* \right)\left( \alpha^T \tau_n^* - \alpha^T \tau \right) | T \right) = \\
		= 2 E_{\theta} \left(\left( \alpha^T \hat{\tau}_n - \alpha^T \tau_n^* \right)\underbrace{E_{\theta}\left( \alpha^T \tau_n^* - \alpha^T \tau | T \right)}_{=0} \right) = 0
	\end{gathered}$$
	Значит:
	$$D (\alpha^t \hat{\tau}_n) = D_{\theta}(\alpha^T \tau_n^*) + E_{\theta} \left( \alpha^T \hat{\tau}_n - \alpha^T \tau_n^* \right)^2$$
	Следовательно, $\displaystyle D (\alpha^t \hat{\tau}_n) \ge D_{\theta}(\alpha^T \tau_n^*)$ и равенство возможно, если $\alpha^T \hat{\tau}_n = \alpha^T \tau_n^*$ $P_{\theta}$-п.н. $\forall \theta \in \Theta$. Это равносильно $\hat{\tau}_n = \tau_n^*$ $P_{\theta}$-п.н. $\forall \theta \in \Theta$.
\end{Proof}

\begin{conseq}[]\label{cha:7/conseq:2}
	Пусть $T$ - достаточная статистика, и существует оптимальная оценка $\hat{\tau}_n(X)$ для функции $\tau (\theta) \in \mathbb{R}^m$. Тогда $\displaystyle \hat{\tau}_n (X) = \varphi(T)$ $P_{\theta}$-п.н. для некоторой борелевской функции $\varphi$.
\end{conseq}
\begin{Proof}
	Если $\hat{\tau}_n$ - оптимальная, то и $\tau_n^* = E_{\theta} (\hat{\tau}_n | T)$ тоже. Тогда $\displaystyle D_{\theta} \tau_n^* = D_{\theta} \hat{\tau}_n \; \forall \theta \in \Theta$. Значит, в силу пункта $3)$ теоремы \ref{cha:7/the:2} получаем, что $\displaystyle \tau_n^* = \hat{\tau}_n$ $P_{\theta}$-п.н., но $\tau_n^* = \varphi(T)$.
\end{Proof}

Итак, если $T$ - достаточная статистика, то оптимальную оценку $\hat{\tau}_n = \varphi(T)$ функции $\tau(\theta) \in \mathbb{R}^m$ можно искать как решения \red{уравнения несмещенности}:
$$E_{\theta} \varphi(T) = \tau(\theta) \; \forall \theta \in \Theta\eqno(3)$$

\begin{definition}\label{cha:7/def:2}
	Статистика $T(X)$ называется \red{полной}, если из равенства $\displaystyle E_{\theta} \varphi (T(X)) = 0 \; \forall \theta \in \Theta \subseteq \mathbb{R}^k$ следует, что $\varphi(T(X)) = 0$ п.н. по $P_{\theta}$-вероятности $\forall \theta \in \Theta$.
\end{definition}

Пусть $T(X)$ имеет плотность $q(x, \theta)$ по мере $\mu$. Тогда $\varphi(T(X)) = 0$ $P_{\theta}$-п.н. тогда и только тогда, когда
$$\forall \theta \in \Theta \; 0 = P_{\theta} \left( \varphi(T(X)) \not = 0 \right) = E_{\theta} I \left( \varphi(T(X)) \not = 0 \right) = \underset{N_q^{\theta}}{\overset{}{\int}}I(\varphi(s) \not = 0) q(s, \theta) \mu (d s)$$
Отсюда следует, что $\displaystyle I(\varphi(s) \not = 0) = 0$ $\mu$-п.в. на $N_q^{\theta}$, т.е.:
$$\varphi(s) = 0 \; \mu\text{-п.в. на } N_q^{\theta}\eqno(4)$$
\begin{itemize}
	\item[$1)$]
		Пусть $T(X)$ дискретна с множеством значений $\mathcal{X}_t^{\theta}$. Тогда $(4)$ (т.е. полнота) эквивалентна условию $\displaystyle \varphi(s) = 0 \; \forall s \in \mathcal{X}_t^{\theta}$. Т.е. $\varphi(s)$ равна нулю на множетсве значений $T$.
	\item[$2)$]
		Пусть $T(X)$ абсолютно непрерывна по мере Лебега. Тогда $(4)$ эквивалентна условию $\displaystyle \varphi(s) = 0$ п.в. по мере Лебега на $N_q^{\theta}$ $\forall \theta \in \Theta$.
\end{itemize}

\section{Оптимальные оценки при полной статистике и лемма Лемана-Шеффе}\label{cha:7/sec:4}

\begin{lemma}[\blue{об оптимальных оценках при наличии полной достаточной статистики}]\label{cha:7/lemma:1}
	Пусть $T$ - полная достаточная для $\theta$ статистика. Тогда:
	\begin{itemize}
		\item[$1)$]
			Если уравнение несмещенности $(3)$ имеет решение, то оно $P_{\theta}$-п.н. единственно. Если это решение имеет конечную ковариационную матрицу, то это опатимальная оценка $\tau(\theta)$.
		\item[$2)$]
			Если уравнение несмещенности $(3)$ не имеет решений, то нет оптимальных оценков для $\tau(\theta)$. Более того, нет даже несмещенных оценок $\tau(\theta)$.
		\item[$3)$]
			Если $\hat{\tau}_n$ - несмещенная оценка $\tau(\theta)$ с конечной ковариационной матрицей, то $\displaystyle \tau_n^* := E_{\theta} (\hat{\tau}_n | T)$ есть оптимальная оценка для $\tau (\theta)$.
	\end{itemize}
\end{lemma}
\begin{Proof}
	Докажем утверждения по пунктам.
	\begin{itemize}
		\item[$1)$]
			Пусть $\varphi(T)$ и $\varphi_1(T)$ - два решения уравнения $(3)$. Тогда $\displaystyle E_{\theta} \left[ \varphi(T) - \varphi_1(T) \right] = 0 \; \forall \theta \in \Theta$. В силу полноты статистики $T$ $\varphi(T) = \varphi_1(T)$ $P_{\theta}$-п.н. $\forall \theta \in \Theta$. Т.е. решение $(3)$ $P_{\theta}$-п.н. единственно, но если решение одно (т.е. есть одна несмещенная оценка вида $\varphi(T)$) и имеет конечную ковариацию, то это и есть оптимальная оценка.
		\item[$2)$]
			Если бы существовала несмещенная оценка $\hat{\tau}_n (X)$, то $\varphi(T) := E_{\theta}(\hat{\tau}_n | T)$ тоже была бы несмещенной оценкой $\tau (\theta)$, т.к. $\displaystyle E_{\theta} \varphi(T) = E_{\theta} E_{\theta} (\hat{\tau}_n |T) = E_{\theta}\hat{\tau}_n = \tau (\theta) \; \forall \theta \in \Theta$. Но тогда $\varphi(T)$ - решение $(3)$ - получаем противоречие.
		\item[$3)$]
			$\displaystyle E_{\theta} \tau_n^* = E_{\theta} E_{\theta} (\hat{\tau}_n |T) = E_{\theta}\hat{\tau}_n = \tau (\theta)$. Т.е. $\tau_n^* = \tau_n^* (T)$ удовлетворяет $(3)$ и имеет конечную ковариационную матрицу. Осталось применить пункт $1)$.
	\end{itemize}
\end{Proof}

\begin{lemma}[\red{Лемана-Шеффе}]\label{cha:7/lemma:2}
	Пусть $T$ - полная достаточная статистика, а борелевская функция $g(T)$ имеет конечную ковариационную матрицу. Тогда $g(T)$ есть оценка своего математического ожидания $\displaystyle \tau(\theta) = E_{\theta} g(T)$.
\end{lemma}

Утверждение леммы \ref{cha:7/lemma:2} следует из пункта $1)$ леммы \ref{cha:7/lemma:1}, т.к. $g(T)$ удовлетворяет уравнению несмещенности $(3)$.

\begin{example}
	Пусть $X = (X_1, \dots, X_n)$, $\{X_i\}$ - н.о.р., $X_1 \sim Pois (\theta), \; \theta > 0$. Указать полную достаточную статистику и найти оптимальные оценки функций $\tau_1(\theta) = \theta^2, \; \tau_2 (\theta) = \theta$.
\end{example}
\begin{solution}
	Мы знаем, что $\displaystyle T(X) = \underset{i=1}{\overset{n}{\sum}}X_i$ - достаточная статистика, $T(X) \sim Pois (n \theta)$.
	\begin{itemize}
		\item[$\bullet$]
			Проверим полноту $T(X)$. Если $\displaystyle E_{\theta} \varphi(T) = 0 \; \forall \theta > 0$, то ёто эквивалентно условию $\displaystyle \underset{k \ge 0}{\overset{}{\sum}}\varphi(k) \frac{(n \theta)^k}{k!} e^{-n \theta} = 0 \; \forall \theta > 0$. Т.е. $\displaystyle \underset{k \ge 0}{\overset{}{\sum}}\frac{\varphi(k) n^k}{k!}\theta^k = 0 \; \forall \theta > 0$. Но если степенной ряд на невырожденном множетсве равен тождественно нулю, то его коэффициенты равны нулю, т.е. $\displaystyle \frac{\varphi(k) n^k}{k!} = 0, \; \varphi(k) = 0$. Таким образом, полнота доказана.
		\item[$\bullet$]
			Уравнение несмещенности для $\tau_1 (\theta)$:
			$$\begin{gathered}
				E_{\theta} \varphi(T) = \tau_1 (\theta), \; \underset{k \ge 0}{\overset{}{\sum}}\varphi(k) \frac{(n \theta)^k}{k!} e^{- n \theta} = \theta^2 \\
				\underset{k \ge 0}{\overset{}{\sum}}\frac{\varphi(k) n^k}{k!} \theta^k = \theta^2 e^{n \theta} = \underset{s \ge 0}{\overset{}{\sum}}\frac{n^s}{k!}\theta^{s+2} = \underset{l \ge 2}{\overset{}{\sum}}\frac{n^{l-2}}{(l-2)!}\theta^l \; \forall \theta > 0
			\end{gathered}$$
			Значит, $\varphi(0) = \varphi(1) = 0$. Для $k \ge 2$ $\displaystyle \frac{\varphi(k) n^k}{k!} = \frac{n^{k-2}}{(k-2)!}$, т.е. $\displaystyle \varphi(k) = \frac{k(k-1)}{n^2}$, $\displaystyle \varphi(T) = \frac{T(T-1)}{n^2}$. Очевидно, что $\displaystyle E_{\theta} \varphi^2(T) < \infty$, т.е. $\varphi(T)$ - оптимальная оценка $\varphi_1(\theta)$.
		\item[$\bullet$]
			$\hat{\tau}_n (X) = X_1$ - несмещенная оценка для $\tau_2(\theta) = \theta$. Оптимальная оценка для $\tau_2(\theta) = \theta$ есть $\displaystyle \varphi(T) = E_{\theta} (X_1 | \underset{}{\overset{}{\sum}}X_i) = \overline{X}$. Т.к. $\displaystyle D_{\theta}\overline{X} = \frac{\theta}{n} < \infty$, то $\overline{X}$ - оптимальная оценка для $\tau_2(\theta) = \theta$.
	\end{itemize}
\end{solution}

\begin{example}
	$X = (X_1, \dots, X_n)$, $\{X_i\}$ - н.о.р., $X_1 \sim R(0, \theta), \; \theta > 0$. Построить оптимальную оценку $\tau(\theta) = \theta$.
\end{example}
\begin{solution}
	Знаем, что $X_{(n)} = T(X)$ - достаточная статистика. Здесь $X_{(1)} \le X_{(2)} \le \dots \le X_{(n)}$ - вариационный ряд. 
	\begin{itemize}
		\item[$\bullet$]
			Докажем, что $T(X) = X_{(n)}$ - полная статистика.
			$$\begin{gathered}
				F_T (x) = P_{\theta} (X_{(n)} \le x) = P_{\theta} (X_1 \le x, \dots, X_n \le x) = \\
				= \underset{i=1}{\overset{n}{\Pi}}P(X_i \le x) = \left( \frac{x}{\theta} \right)^n \text{ при } 0 \le x \le \theta
			\end{gathered}$$
			Плотность вероятности (существует!):
			$$f_T (x, \theta) = \begin{cases}
				F'_t (x, \theta) = \frac{n x^{n-1}}{\theta^n} \text{ при } 0 \le x \le \theta \\
				0, \text{ при прочих } x
			\end{cases}$$
			Если $\displaystyle E_{\theta} \varphi(T) = \underset{0}{\overset{\theta}{\int}}\varphi(x) f_T(x, \theta) dx = \underset{0}{\overset{\theta}{\int}}\varphi(x) \frac{n x^{n-1}}{\theta^n}dx = 0 \; \forall \theta > 0$, то $\displaystyle \varphi(\theta) \theta^{n-1} = 0$ п.в., т.е. $\displaystyle \varphi(\theta) = 0$ п.в. для $\theta > 0$. Таким образом, статистика $T(X) = X_{(n)}$ - полная!
		\item[$\bullet$]
			Уравнение несмещенности для $\tau(\theta) = \theta$ имеет вид $\displaystyle E_{\theta} \varphi(T) = \underset{0}{\overset{\theta}{\int}}\varphi(x) \frac{n x^{n-1}}{\theta^n}dx = \theta$, т.е. $\displaystyle \underset{0}{\overset{\theta}{\int}}\varphi(x) n x^{n-1} dx = \theta^{n+1}$, $\displaystyle \varphi(\theta) \theta^{n-1} = (n+1) \theta^n$ п.в. Отсюда получаем: $\displaystyle \varphi(X_{(n)}) = \frac{n+1}{n}X_{(n)}$.
	\end{itemize}
\end{solution}



















